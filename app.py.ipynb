{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import streamlit as st\nimport pandas as pd\nimport numpy as np\nimport pickle\nimport os\n\n# ============================================================================\n# 1. LOAD MODEL AND SCALER\n# ============================================================================\n\n# Assuming the model and scaler files are in the same directory as app.py\ntry:\n    with open('svm_cancer_model.pkl', 'rb') as model_file:\n        model = pickle.load(model_file)\nexcept FileNotFoundError:\n    st.error(\"Error: 'svm_cancer_model.pkl' file not found. Please ensure the trained model file is in the same directory.\")\n    model = None\n\ntry:\n    with open('scaler_cancer.pkl', 'rb') as scaler_file:\n        scaler = pickle.load(scaler_file)\nexcept FileNotFoundError:\n    st.error(\"Error: 'scaler_cancer.pkl' file not found. Please ensure the scaler file is in the same directory.\")\n    scaler = None\n\n# List of all 30 features (must match training data order)\nFEATURE_NAMES = [\n    'radius_mean', 'texture_mean', 'perimeter_mean', 'area_mean', 'smoothness_mean', \n    'compactness_mean', 'concavity_mean', 'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean',\n    'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se', \n    'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se', 'fractal_dimension_se',\n    'radius_worst', 'texture_worst', 'perimeter_worst', 'area_worst', 'smoothness_worst', \n    'compactness_worst', 'concavity_worst', 'concave points_worst', 'symmetry_worst', 'fractal_dimension_worst'\n]\n\n\n# ============================================================================\n# 2. STREAMLIT APP LAYOUT\n# ============================================================================\n\nst.set_page_config(page_title=\"Breast Cancer Prediction (SVM)\", layout=\"wide\")\n\nst.title(\"üéÄ Breast Cancer Prediction using SVM\")\nst.markdown(\"---\")\n\nif model is None or scaler is None:\n    st.warning(\"Prediction cannot proceed. Please resolve the file loading errors above.\")\nelse:\n    st.sidebar.header(\"Patient Feature Input\")\n    st.sidebar.markdown(\"Please input the 30 cellular feature measurements.\")\n\n    # Dictionary to store user inputs\n    input_data = {}\n    \n    # ------------------\n    # INPUT SECTION: Mean Values (10 features)\n    # ------------------\n    st.sidebar.subheader(\"A) Mean Values\")\n    \n    mean_cols = st.sidebar.columns(2)\n    \n    # Function to create input fields\n    def get_input(feature, label, default_value, min_value=0.0):\n        if 'mean' in feature:\n            step = 0.001\n        elif 'se' in feature:\n            step = 0.0001\n        else: # worst\n            step = 0.01\n\n        return st.sidebar.number_input(\n            label=f\"{label} ({feature})\",\n            value=default_value,\n            min_value=min_value,\n            step=step,\n            format=\"%.4f\",\n            key=feature\n        )\n\n    # Example means (often around 10-20)\n    input_data['radius_mean'] = mean_cols[0].number_input(\"Radius (Mean)\", value=14.127, min_value=0.0, step=0.1, format=\"%.3f\")\n    input_data['texture_mean'] = mean_cols[1].number_input(\"Texture (Mean)\", value=19.29, min_value=0.0, step=0.1, format=\"%.2f\")\n    \n    input_data['perimeter_mean'] = get_input('perimeter_mean', 'Perimeter', 91.969)\n    input_data['area_mean'] = get_input('area_mean', 'Area', 654.889)\n    input_data['smoothness_mean'] = get_input('smoothness_mean', 'Smoothness', 0.0963)\n    input_data['compactness_mean'] = get_input('compactness_mean', 'Compactness', 0.1043)\n    input_data['concavity_mean'] = get_input('concavity_mean', 'Concavity', 0.0888)\n    input_data['concave points_mean'] = get_input('concave points_mean', 'Concave Points', 0.0489)\n    input_data['symmetry_mean'] = get_input('symmetry_mean', 'Symmetry', 0.1811)\n    input_data['fractal_dimension_mean'] = get_input('fractal_dimension_mean', 'Fractal Dimension', 0.0628)\n    \n    # ------------------\n    # INPUT SECTION: Standard Error (10 features)\n    # ------------------\n    st.sidebar.subheader(\"B) Standard Error (SE) Values\")\n    \n    input_data['radius_se'] = get_input('radius_se', 'Radius (SE)', 0.405)\n    input_data['texture_se'] = get_input('texture_se', 'Texture (SE)', 1.216)\n    input_data['perimeter_se'] = get_input('perimeter_se', 'Perimeter (SE)', 2.866)\n    input_data['area_se'] = get_input('area_se', 'Area (SE)', 40.337)\n    input_data['smoothness_se'] = get_input('smoothness_se', 'Smoothness (SE)', 0.0070)\n    input_data['compactness_se'] = get_input('compactness_se', 'Compactness (SE)', 0.0254)\n    input_data['concavity_se'] = get_input('concavity_se', 'Concavity (SE)', 0.0318)\n    input_data['concave points_se'] = get_input('concave points_se', 'Concave Points (SE)', 0.0117)\n    input_data['symmetry_se'] = get_input('symmetry_se', 'Symmetry (SE)', 0.0205)\n    input_data['fractal_dimension_se'] = get_input('fractal_dimension_se', 'Fractal Dimension (SE)', 0.0038)\n\n    # ------------------\n    # INPUT SECTION: Worst/Largest Values (10 features)\n    # ------------------\n    st.sidebar.subheader(\"C) Worst/Largest Values\")\n\n    input_data['radius_worst'] = get_input('radius_worst', 'Radius (Worst)', 16.269)\n    input_data['texture_worst'] = get_input('texture_worst', 'Texture (Worst)', 25.677)\n    input_data['perimeter_worst'] = get_input('perimeter_worst', 'Perimeter (Worst)', 107.26)\n    input_data['area_worst'] = get_input('area_worst', 'Area (Worst)', 880.583)\n    input_data['smoothness_worst'] = get_input('smoothness_worst', 'Smoothness (Worst)', 0.1323)\n    input_data['compactness_worst'] = get_input('compactness_worst', 'Compactness (Worst)', 0.2542)\n    input_data['concavity_worst'] = get_input('concavity_worst', 'Concavity (Worst)', 0.2721)\n    input_data['concave points_worst'] = get_input('concave points_worst', 'Concave Points (Worst)', 0.1146)\n    input_data['symmetry_worst'] = get_input('symmetry_worst', 'Symmetry (Worst)', 0.2901)\n    input_data['fractal_dimension_worst'] = get_input('fractal_dimension_worst', 'Fractal Dimension (Worst)', 0.0839)\n\n    # Create the DataFrame in the correct order\n    input_df = pd.DataFrame([input_data], columns=FEATURE_NAMES)\n    \n    # ------------------\n    # Display Input Data\n    # ------------------\n    st.subheader(\"Current Input Data (30 Features)\")\n    st.dataframe(input_df.T, use_container_width=True)\n\n\n    # ============================================================================\n    # 3. PREDICTION LOGIC\n    # ============================================================================\n\n    st.subheader(\"Prediction Result\")\n    \n    if st.button(\"Analyze Cell Data\"):\n        \n        with st.spinner('Analyzing features...'):\n            try:\n                # 1. Scale the input data\n                input_scaled = scaler.transform(input_df)\n                \n                # 2. Make Prediction\n                prediction = model.predict(input_scaled)\n                \n                # 3. Interpret Result\n                if prediction[0] == 1:\n                    result = \"Malignant (Cancerous)\"\n                    st.error(f\"‚ö†Ô∏è Prediction: {result}\")\n                    st.balloons()\n                    st.markdown(\"Based on the input features, the model predicts the mass is **Malignant (Cancerous)**. **Consult a specialist immediately.**\")\n                else:\n                    result = \"Benign (Non-Cancerous)\"\n                    st.success(f\"‚úÖ Prediction: {result}\")\n                    st.markdown(\"Based on the input features, the model predicts the mass is **Benign (Non-Cancerous)**. Regular follow-up is advised.\")\n\n                st.markdown(\"---\")\n                st.info(\"The model used is a Support Vector Classifier (SVC) with an RBF kernel, trained on the scaled Wisconsin Diagnostic Breast Cancer dataset.\")\n\n            except Exception as e:\n                st.exception(f\"An error occurred during prediction: {e}\")\n\n# Footer for running instructions\nst.markdown(\"---\")\nst.markdown(\"\"\"\n### üöÄ How to Run This App:\n1.  **Ensure files are present:** Make sure `svm_cancer_model.pkl` and `scaler_cancer.pkl` are in the same folder as this `app.py` file.\n2.  **Install Streamlit:** `pip install streamlit pandas scikit-learn`\n3.  **Run the app:** Open your terminal in the file's directory and type: `streamlit run app.py`\n\"\"\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}